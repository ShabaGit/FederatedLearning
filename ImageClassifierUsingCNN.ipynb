{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This script contains all the necessary code to develop, train, and evaluate a handwritten digit classifier using CNN on the MNIST dataset."
      ],
      "metadata": {
        "id": "C_ENgOMdzPDM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yonedtTGtmLp",
        "outputId": "1371b8b4-95c3-40da-b0e6-3bc496100db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "844/844 [==============================] - 49s 56ms/step - loss: 0.1815 - accuracy: 0.9446 - val_loss: 0.0616 - val_accuracy: 0.9820\n",
            "Epoch 2/100\n",
            "844/844 [==============================] - 51s 61ms/step - loss: 0.0503 - accuracy: 0.9848 - val_loss: 0.0350 - val_accuracy: 0.9887\n",
            "Epoch 3/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0349 - val_accuracy: 0.9895\n",
            "Epoch 4/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
            "Epoch 5/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0296 - val_accuracy: 0.9913\n",
            "Epoch 6/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0271 - val_accuracy: 0.9920\n",
            "Epoch 7/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
            "Epoch 8/100\n",
            "844/844 [==============================] - 46s 54ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0302 - val_accuracy: 0.9917\n",
            "Epoch 9/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0339 - val_accuracy: 0.9913\n",
            "Epoch 10/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0365 - val_accuracy: 0.9900\n",
            "Epoch 11/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0403 - val_accuracy: 0.9910\n",
            "Epoch 12/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0463 - val_accuracy: 0.9890\n",
            "Epoch 13/100\n",
            "844/844 [==============================] - 46s 54ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0411 - val_accuracy: 0.9913\n",
            "Epoch 14/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0436 - val_accuracy: 0.9907\n",
            "Epoch 15/100\n",
            "844/844 [==============================] - 46s 54ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0388 - val_accuracy: 0.9932\n",
            "Epoch 16/100\n",
            "844/844 [==============================] - 44s 53ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0340 - val_accuracy: 0.9937\n",
            "Epoch 17/100\n",
            "844/844 [==============================] - 47s 56ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0323 - val_accuracy: 0.9935\n",
            "Epoch 18/100\n",
            "844/844 [==============================] - 46s 54ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0328 - val_accuracy: 0.9925\n",
            "Epoch 19/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0430 - val_accuracy: 0.9922\n",
            "Epoch 20/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0366 - val_accuracy: 0.9918\n",
            "Epoch 21/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0353 - val_accuracy: 0.9917\n",
            "Epoch 22/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0370 - val_accuracy: 0.9918\n",
            "Epoch 23/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0532 - val_accuracy: 0.9903\n",
            "Epoch 24/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0581 - val_accuracy: 0.9897\n",
            "Epoch 25/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0482 - val_accuracy: 0.9917\n",
            "Epoch 26/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0591 - val_accuracy: 0.9900\n",
            "Epoch 27/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
            "Epoch 28/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0712 - val_accuracy: 0.9892\n",
            "Epoch 29/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0464 - val_accuracy: 0.9910\n",
            "Epoch 30/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0505 - val_accuracy: 0.9917\n",
            "Epoch 31/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0635 - val_accuracy: 0.9902\n",
            "Epoch 32/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0929 - val_accuracy: 0.9885\n",
            "Epoch 33/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0464 - val_accuracy: 0.9915\n",
            "Epoch 34/100\n",
            "844/844 [==============================] - 47s 55ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0587 - val_accuracy: 0.9902\n",
            "Epoch 35/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0634 - val_accuracy: 0.9902\n",
            "Epoch 36/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0468 - val_accuracy: 0.9923\n",
            "Epoch 37/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0596 - val_accuracy: 0.9900\n",
            "Epoch 38/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0844 - val_accuracy: 0.9903\n",
            "Epoch 39/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0595 - val_accuracy: 0.9908\n",
            "Epoch 40/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0491 - val_accuracy: 0.9927\n",
            "Epoch 41/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0644 - val_accuracy: 0.9912\n",
            "Epoch 42/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0554 - val_accuracy: 0.9925\n",
            "Epoch 43/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0669 - val_accuracy: 0.9910\n",
            "Epoch 44/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0839 - val_accuracy: 0.9888\n",
            "Epoch 45/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0623 - val_accuracy: 0.9897\n",
            "Epoch 46/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0611 - val_accuracy: 0.9907\n",
            "Epoch 47/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0524 - val_accuracy: 0.9912\n",
            "Epoch 48/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0694 - val_accuracy: 0.9897\n",
            "Epoch 49/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0499 - val_accuracy: 0.9923\n",
            "Epoch 50/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0804 - val_accuracy: 0.9905\n",
            "Epoch 51/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0583 - val_accuracy: 0.9930\n",
            "Epoch 52/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0665 - val_accuracy: 0.9908\n",
            "Epoch 53/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0848 - val_accuracy: 0.9880\n",
            "Epoch 54/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0667 - val_accuracy: 0.9908\n",
            "Epoch 55/100\n",
            "844/844 [==============================] - 45s 53ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0700 - val_accuracy: 0.9907\n",
            "Epoch 56/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0771 - val_accuracy: 0.9900\n",
            "Epoch 57/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0695 - val_accuracy: 0.9898\n",
            "Epoch 58/100\n",
            "844/844 [==============================] - 46s 54ms/step - loss: 8.3470e-04 - accuracy: 0.9998 - val_loss: 0.0643 - val_accuracy: 0.9923\n",
            "Epoch 59/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 9.6464e-04 - accuracy: 0.9997 - val_loss: 0.0841 - val_accuracy: 0.9910\n",
            "Epoch 60/100\n",
            "844/844 [==============================] - 45s 54ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0820 - val_accuracy: 0.9907\n",
            "Epoch 61/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0931 - val_accuracy: 0.9898\n",
            "Epoch 62/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0956 - val_accuracy: 0.9905\n",
            "Epoch 63/100\n",
            "844/844 [==============================] - 46s 55ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0841 - val_accuracy: 0.9903\n",
            "Epoch 64/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0946 - val_accuracy: 0.9898\n",
            "Epoch 65/100\n",
            "844/844 [==============================] - 50s 60ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0939 - val_accuracy: 0.9912\n",
            "Epoch 66/100\n",
            "844/844 [==============================] - 54s 64ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0899 - val_accuracy: 0.9917\n",
            "Epoch 67/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1019 - val_accuracy: 0.9912\n",
            "Epoch 68/100\n",
            "844/844 [==============================] - 52s 61ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0895 - val_accuracy: 0.9908\n",
            "Epoch 69/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0905 - val_accuracy: 0.9910\n",
            "Epoch 70/100\n",
            "844/844 [==============================] - 47s 56ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0975 - val_accuracy: 0.9903\n",
            "Epoch 71/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 4.5438e-04 - accuracy: 0.9999 - val_loss: 0.0928 - val_accuracy: 0.9920\n",
            "Epoch 72/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 8.1747e-04 - accuracy: 0.9998 - val_loss: 0.1022 - val_accuracy: 0.9910\n",
            "Epoch 73/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0851 - val_accuracy: 0.9913\n",
            "Epoch 74/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0792 - val_accuracy: 0.9918\n",
            "Epoch 75/100\n",
            "844/844 [==============================] - 48s 56ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0928 - val_accuracy: 0.9910\n",
            "Epoch 76/100\n",
            "844/844 [==============================] - 52s 61ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0691 - val_accuracy: 0.9923\n",
            "Epoch 77/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0846 - val_accuracy: 0.9925\n",
            "Epoch 78/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0851 - val_accuracy: 0.9922\n",
            "Epoch 79/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0984 - val_accuracy: 0.9913\n",
            "Epoch 80/100\n",
            "844/844 [==============================] - 47s 56ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.1041 - val_accuracy: 0.9910\n",
            "Epoch 81/100\n",
            "844/844 [==============================] - 47s 56ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1075 - val_accuracy: 0.9907\n",
            "Epoch 82/100\n",
            "844/844 [==============================] - 51s 60ms/step - loss: 5.6937e-04 - accuracy: 0.9998 - val_loss: 0.0980 - val_accuracy: 0.9907\n",
            "Epoch 83/100\n",
            "844/844 [==============================] - 51s 60ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0787 - val_accuracy: 0.9917\n",
            "Epoch 84/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0737 - val_accuracy: 0.9932\n",
            "Epoch 85/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 5.3132e-04 - accuracy: 0.9998 - val_loss: 0.1079 - val_accuracy: 0.9898\n",
            "Epoch 86/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1003 - val_accuracy: 0.9922\n",
            "Epoch 87/100\n",
            "844/844 [==============================] - 47s 56ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0872 - val_accuracy: 0.9923\n",
            "Epoch 88/100\n",
            "844/844 [==============================] - 51s 61ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1098 - val_accuracy: 0.9897\n",
            "Epoch 89/100\n",
            "844/844 [==============================] - 50s 60ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0989 - val_accuracy: 0.9900\n",
            "Epoch 90/100\n",
            "844/844 [==============================] - 48s 57ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0930 - val_accuracy: 0.9910\n",
            "Epoch 91/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0893 - val_accuracy: 0.9918\n",
            "Epoch 92/100\n",
            "844/844 [==============================] - 48s 56ms/step - loss: 7.4161e-06 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9913\n",
            "Epoch 93/100\n",
            "844/844 [==============================] - 48s 57ms/step - loss: 1.6564e-06 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9913\n",
            "Epoch 94/100\n",
            "844/844 [==============================] - 52s 62ms/step - loss: 1.1726e-06 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9913\n",
            "Epoch 95/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 8.4401e-07 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9913\n",
            "Epoch 96/100\n",
            "844/844 [==============================] - 51s 60ms/step - loss: 6.0768e-07 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9917\n",
            "Epoch 97/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 4.3053e-07 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9920\n",
            "Epoch 98/100\n",
            "844/844 [==============================] - 50s 59ms/step - loss: 3.0108e-07 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9920\n",
            "Epoch 99/100\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 2.0869e-07 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9922\n",
            "Epoch 100/100\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 1.4293e-07 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9922\n",
            "313/313 [==============================] - 3s 11ms/step\n",
            "Accuracy: 0.9928\n",
            "Precision: 0.9928048871489514\n",
            "Recall: 0.9928\n",
            "F1 Score: 0.992799862243682\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the data\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Define CNN Architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_val, y_val))\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code extends the baseline model by incorporating dropout, batch normalization, and data augmentation techniques. It then trains the finalized model on the entire training dataset and evaluates its performance on the test dataset. Finally, it prints the test accuracy and other performance metrics."
      ],
      "metadata": {
        "id": "_osnMrVQy5MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define Finalized CNN Architecture\n",
        "final_model = Sequential()\n",
        "final_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "final_model.add(BatchNormalization())\n",
        "final_model.add(MaxPooling2D((2, 2)))\n",
        "final_model.add(Dropout(0.25))\n",
        "\n",
        "final_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "final_model.add(BatchNormalization())\n",
        "final_model.add(MaxPooling2D((2, 2)))\n",
        "final_model.add(Dropout(0.25))\n",
        "\n",
        "final_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "final_model.add(BatchNormalization())\n",
        "final_model.add(Flatten())\n",
        "final_model.add(Dropout(0.5))\n",
        "\n",
        "final_model.add(Dense(64, activation='relu'))\n",
        "final_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the Final Model\n",
        "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Train the Final Model\n",
        "final_history = final_model.fit(datagen.flow(x_train, y_train, batch_size=64), epochs=100, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Final Model on Test Data\n",
        "final_scores = final_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Test Accuracy:\", final_scores[1])\n",
        "\n",
        "# Predict probabilities for test data\n",
        "y_pred_proba = final_model.predict(x_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "final_model.save('/content/final_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzTYgrYCO_yu",
        "outputId": "22833dc0-9917-4759-99bd-10923f2e11f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "844/844 [==============================] - 87s 99ms/step - loss: 0.4905 - accuracy: 0.8436 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
            "Epoch 2/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.1716 - accuracy: 0.9463 - val_loss: 0.0789 - val_accuracy: 0.9768\n",
            "Epoch 3/100\n",
            "844/844 [==============================] - 81s 96ms/step - loss: 0.1343 - accuracy: 0.9581 - val_loss: 0.0712 - val_accuracy: 0.9790\n",
            "Epoch 4/100\n",
            "844/844 [==============================] - 85s 101ms/step - loss: 0.1129 - accuracy: 0.9655 - val_loss: 0.0387 - val_accuracy: 0.9863\n",
            "Epoch 5/100\n",
            "844/844 [==============================] - 82s 98ms/step - loss: 0.0996 - accuracy: 0.9693 - val_loss: 0.0642 - val_accuracy: 0.9813\n",
            "Epoch 6/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0896 - accuracy: 0.9721 - val_loss: 0.0365 - val_accuracy: 0.9887\n",
            "Epoch 7/100\n",
            "844/844 [==============================] - 85s 101ms/step - loss: 0.0893 - accuracy: 0.9727 - val_loss: 0.0283 - val_accuracy: 0.9913\n",
            "Epoch 8/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0827 - accuracy: 0.9744 - val_loss: 0.0338 - val_accuracy: 0.9893\n",
            "Epoch 9/100\n",
            "844/844 [==============================] - 91s 107ms/step - loss: 0.0790 - accuracy: 0.9762 - val_loss: 0.0390 - val_accuracy: 0.9887\n",
            "Epoch 10/100\n",
            "844/844 [==============================] - 89s 106ms/step - loss: 0.0742 - accuracy: 0.9772 - val_loss: 0.0319 - val_accuracy: 0.9903\n",
            "Epoch 11/100\n",
            "844/844 [==============================] - 90s 106ms/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 0.0272 - val_accuracy: 0.9920\n",
            "Epoch 12/100\n",
            "844/844 [==============================] - 90s 107ms/step - loss: 0.0711 - accuracy: 0.9782 - val_loss: 0.0276 - val_accuracy: 0.9908\n",
            "Epoch 13/100\n",
            "844/844 [==============================] - 90s 106ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0285 - val_accuracy: 0.9915\n",
            "Epoch 14/100\n",
            "844/844 [==============================] - 90s 106ms/step - loss: 0.0670 - accuracy: 0.9793 - val_loss: 0.0276 - val_accuracy: 0.9912\n",
            "Epoch 15/100\n",
            "844/844 [==============================] - 92s 109ms/step - loss: 0.0627 - accuracy: 0.9806 - val_loss: 0.0251 - val_accuracy: 0.9928\n",
            "Epoch 16/100\n",
            "844/844 [==============================] - 89s 106ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0282 - val_accuracy: 0.9917\n",
            "Epoch 17/100\n",
            "844/844 [==============================] - 90s 106ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 0.0283 - val_accuracy: 0.9920\n",
            "Epoch 18/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0576 - accuracy: 0.9820 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
            "Epoch 19/100\n",
            "844/844 [==============================] - 90s 106ms/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.0260 - val_accuracy: 0.9925\n",
            "Epoch 20/100\n",
            "844/844 [==============================] - 88s 105ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 0.0262 - val_accuracy: 0.9917\n",
            "Epoch 21/100\n",
            "844/844 [==============================] - 89s 105ms/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.0248 - val_accuracy: 0.9927\n",
            "Epoch 22/100\n",
            "844/844 [==============================] - 90s 106ms/step - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.0188 - val_accuracy: 0.9938\n",
            "Epoch 23/100\n",
            "844/844 [==============================] - 91s 107ms/step - loss: 0.0545 - accuracy: 0.9831 - val_loss: 0.0247 - val_accuracy: 0.9913\n",
            "Epoch 24/100\n",
            "844/844 [==============================] - 83s 99ms/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.0229 - val_accuracy: 0.9932\n",
            "Epoch 25/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.0270 - val_accuracy: 0.9920\n",
            "Epoch 26/100\n",
            "844/844 [==============================] - 83s 99ms/step - loss: 0.0528 - accuracy: 0.9830 - val_loss: 0.0214 - val_accuracy: 0.9930\n",
            "Epoch 27/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0505 - accuracy: 0.9845 - val_loss: 0.0257 - val_accuracy: 0.9915\n",
            "Epoch 28/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0227 - val_accuracy: 0.9942\n",
            "Epoch 29/100\n",
            "844/844 [==============================] - 82s 98ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.0250 - val_accuracy: 0.9927\n",
            "Epoch 30/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.0243 - val_accuracy: 0.9937\n",
            "Epoch 31/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.0254 - val_accuracy: 0.9925\n",
            "Epoch 32/100\n",
            "844/844 [==============================] - 82s 98ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.0245 - val_accuracy: 0.9935\n",
            "Epoch 33/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.0231 - val_accuracy: 0.9935\n",
            "Epoch 34/100\n",
            "844/844 [==============================] - 85s 101ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 0.0261 - val_accuracy: 0.9922\n",
            "Epoch 35/100\n",
            "844/844 [==============================] - 84s 99ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.0219 - val_accuracy: 0.9927\n",
            "Epoch 36/100\n",
            "844/844 [==============================] - 81s 96ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0273 - val_accuracy: 0.9915\n",
            "Epoch 37/100\n",
            "844/844 [==============================] - 84s 99ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.0200 - val_accuracy: 0.9935\n",
            "Epoch 38/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0236 - val_accuracy: 0.9932\n",
            "Epoch 39/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0449 - accuracy: 0.9856 - val_loss: 0.0212 - val_accuracy: 0.9927\n",
            "Epoch 40/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.0229 - val_accuracy: 0.9935\n",
            "Epoch 41/100\n",
            "844/844 [==============================] - 82s 98ms/step - loss: 0.0447 - accuracy: 0.9858 - val_loss: 0.0240 - val_accuracy: 0.9930\n",
            "Epoch 42/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0252 - val_accuracy: 0.9932\n",
            "Epoch 43/100\n",
            "844/844 [==============================] - 96s 114ms/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 0.0209 - val_accuracy: 0.9932\n",
            "Epoch 44/100\n",
            "844/844 [==============================] - 90s 107ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 0.0205 - val_accuracy: 0.9938\n",
            "Epoch 45/100\n",
            "844/844 [==============================] - 84s 99ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.0266 - val_accuracy: 0.9912\n",
            "Epoch 46/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.0222 - val_accuracy: 0.9937\n",
            "Epoch 47/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 0.0240 - val_accuracy: 0.9928\n",
            "Epoch 48/100\n",
            "844/844 [==============================] - 82s 98ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.0201 - val_accuracy: 0.9932\n",
            "Epoch 49/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.0233 - val_accuracy: 0.9925\n",
            "Epoch 50/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.0233 - val_accuracy: 0.9930\n",
            "Epoch 51/100\n",
            "844/844 [==============================] - 91s 108ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.0210 - val_accuracy: 0.9937\n",
            "Epoch 52/100\n",
            "844/844 [==============================] - 91s 108ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.0230 - val_accuracy: 0.9932\n",
            "Epoch 53/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.0256 - val_accuracy: 0.9937\n",
            "Epoch 54/100\n",
            "844/844 [==============================] - 86s 102ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.0229 - val_accuracy: 0.9938\n",
            "Epoch 55/100\n",
            "844/844 [==============================] - 82s 97ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0217 - val_accuracy: 0.9938\n",
            "Epoch 56/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0205 - val_accuracy: 0.9942\n",
            "Epoch 57/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0201 - val_accuracy: 0.9940\n",
            "Epoch 58/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0202 - val_accuracy: 0.9935\n",
            "Epoch 59/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.0186 - val_accuracy: 0.9932\n",
            "Epoch 60/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0212 - val_accuracy: 0.9938\n",
            "Epoch 61/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.0215 - val_accuracy: 0.9942\n",
            "Epoch 62/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0187 - val_accuracy: 0.9948\n",
            "Epoch 63/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.0203 - val_accuracy: 0.9932\n",
            "Epoch 64/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0370 - accuracy: 0.9888 - val_loss: 0.0209 - val_accuracy: 0.9932\n",
            "Epoch 65/100\n",
            "844/844 [==============================] - 82s 98ms/step - loss: 0.0388 - accuracy: 0.9886 - val_loss: 0.0199 - val_accuracy: 0.9952\n",
            "Epoch 66/100\n",
            "844/844 [==============================] - 84s 99ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.0224 - val_accuracy: 0.9938\n",
            "Epoch 67/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.0178 - val_accuracy: 0.9943\n",
            "Epoch 68/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.0207 - val_accuracy: 0.9940\n",
            "Epoch 69/100\n",
            "844/844 [==============================] - 86s 101ms/step - loss: 0.0387 - accuracy: 0.9880 - val_loss: 0.0207 - val_accuracy: 0.9935\n",
            "Epoch 70/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0388 - accuracy: 0.9881 - val_loss: 0.0203 - val_accuracy: 0.9943\n",
            "Epoch 71/100\n",
            "844/844 [==============================] - 83s 99ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
            "Epoch 72/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0196 - val_accuracy: 0.9937\n",
            "Epoch 73/100\n",
            "844/844 [==============================] - 83s 98ms/step - loss: 0.0369 - accuracy: 0.9890 - val_loss: 0.0182 - val_accuracy: 0.9940\n",
            "Epoch 74/100\n",
            "844/844 [==============================] - 83s 99ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.0183 - val_accuracy: 0.9940\n",
            "Epoch 75/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0234 - val_accuracy: 0.9918\n",
            "Epoch 76/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0385 - accuracy: 0.9886 - val_loss: 0.0218 - val_accuracy: 0.9927\n",
            "Epoch 77/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.0202 - val_accuracy: 0.9942\n",
            "Epoch 78/100\n",
            "844/844 [==============================] - 84s 99ms/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0204 - val_accuracy: 0.9942\n",
            "Epoch 79/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.0187 - val_accuracy: 0.9942\n",
            "Epoch 80/100\n",
            "844/844 [==============================] - 86s 102ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.0190 - val_accuracy: 0.9948\n",
            "Epoch 81/100\n",
            "844/844 [==============================] - 86s 101ms/step - loss: 0.0356 - accuracy: 0.9889 - val_loss: 0.0194 - val_accuracy: 0.9943\n",
            "Epoch 82/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.0214 - val_accuracy: 0.9928\n",
            "Epoch 83/100\n",
            "844/844 [==============================] - 88s 105ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.0218 - val_accuracy: 0.9938\n",
            "Epoch 84/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0175 - val_accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "844/844 [==============================] - 86s 101ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.0203 - val_accuracy: 0.9942\n",
            "Epoch 86/100\n",
            "844/844 [==============================] - 86s 102ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0213 - val_accuracy: 0.9933\n",
            "Epoch 87/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.0209 - val_accuracy: 0.9942\n",
            "Epoch 88/100\n",
            "844/844 [==============================] - 86s 102ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.0211 - val_accuracy: 0.9943\n",
            "Epoch 89/100\n",
            "844/844 [==============================] - 83s 99ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 0.0201 - val_accuracy: 0.9943\n",
            "Epoch 90/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.0188 - val_accuracy: 0.9943\n",
            "Epoch 91/100\n",
            "844/844 [==============================] - 83s 99ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0209 - val_accuracy: 0.9945\n",
            "Epoch 92/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0173 - val_accuracy: 0.9960\n",
            "Epoch 93/100\n",
            "844/844 [==============================] - 87s 103ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0201 - val_accuracy: 0.9945\n",
            "Epoch 94/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 0.0219 - val_accuracy: 0.9935\n",
            "Epoch 95/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
            "Epoch 96/100\n",
            "844/844 [==============================] - 85s 101ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.0200 - val_accuracy: 0.9943\n",
            "Epoch 97/100\n",
            "844/844 [==============================] - 84s 100ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.0235 - val_accuracy: 0.9942\n",
            "Epoch 98/100\n",
            "844/844 [==============================] - 84s 99ms/step - loss: 0.0342 - accuracy: 0.9897 - val_loss: 0.0192 - val_accuracy: 0.9953\n",
            "Epoch 99/100\n",
            "844/844 [==============================] - 85s 100ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
            "Epoch 100/100\n",
            "844/844 [==============================] - 86s 102ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0189 - val_accuracy: 0.9947\n",
            "Test Accuracy: 0.9957000017166138\n",
            "313/313 [==============================] - 5s 14ms/step\n",
            "Test Accuracy: 0.9957\n",
            "Precision: 0.9957138852453332\n",
            "Recall: 0.9957\n",
            "F1 Score: 0.9957023442426396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below evaluates the performance of the final model on classifying unseen data."
      ],
      "metadata": {
        "id": "ZPzjetTd28SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from tensorflow import keras\n",
        "\n",
        "# Preprocess the new images\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(28, 28), color_mode='grayscale')\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array /= 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Path to the new image\n",
        "image_path = \"/content/three.png\"\n",
        "\n",
        "# Preprocess the image\n",
        "new_image = preprocess_image(image_path)\n",
        "\n",
        "# Load the finalized model\n",
        "final_model = keras.models.load_model('/content/final_model.h5')\n",
        "\n",
        "# Make predictions\n",
        "predictions = final_model.predict(new_image)\n",
        "predicted_class = np.argmax(predictions)\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "\n",
        "# Optionally, you can visualize the prediction\n",
        "plt.imshow(new_image.reshape(28, 28), cmap='gray')\n",
        "plt.title(\"Predicted Class: \" + str(predicted_class))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "gZAW5cSK27Zh",
        "outputId": "5fa2e0f7-0d17-498e-aff9-788498a4ec2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 132ms/step\n",
            "Predicted class: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final model successfully predicts the class of the handwritten digit."
      ],
      "metadata": {
        "id": "m76ft83hdkSK"
      }
    }
  ]
}